Neil Ferguson developed some epidemiological modeling code over many years in his lab for many years. When COVID broke out, he adapted his code to model COVID. Based on this software, he wrote <a href="https://www.imperial.ac.uk/media/imperial-college/medicine/sph/ide/gida-fellowships/Imperial-College-COVID19-NPI-modelling-16-03-2020.pdf">Report 9</a>, which recommended that the UK government institute a lockdown. People all over the world want to see the source code, but he didn't develop it with the intent of releasing it publicly. It was originally one big 25,000 line C++ file, so <a href="https://twitter.com/neil_ferguson/status/1241835456947519492">he got some folks from Microsoft/GitHub</a>, including the legendary John Carmack, to clean up the code, and then they released it on <a href="https://github.com/mrc-ide/covid-sim">GitHub</a>. This is when the trouble started. Several professional engineers wrote a GitHub issue called, "We, the undersigned software engineers, call for any papers based on this codebase to be immediately retracted (<a href="https://github.com/mrc-ide/covid-sim/issues/165">#165</a>)", alleging that the code quality was too low to justify accepting results which would disrupt millions of lives. There was furious public debate, and at this point news organizations started to pick it up. Unfortunately, conspiracy theorists who already wanted to doubt that COVID was real picked this up too. Furthermore, people wanted to see the code that he used in Report 9, not the cleaned-up version. Ferguson repeatedly denied this, until a FOIA request forced him to release it. <a href="https://zenodo.org/record/3865491#.YfsVYFvMLeS">A team from Edinburgh</a> was able to reproduce the same conclusion (although not a bit-equivalent result). That's mostly the end of the news story.

As for the technical matters, the software engineers in issue #165 mainly complained that the software was "messy:" no comments, high coupling, uninformative variable names, only basic tests, use of global state etc. This makes the code difficult to scrutinize and difficult to verify. While this is a valid concern, it does not cause a significant doubt in the conclusion for me. Furthermore, the way these engineers went about raising the issue discourages future scientists from releasing their code.

On the other hand, someone in <a href="https://github.com/mrc-ide/covid-sim/issues/161">issue #161</a> constructively raised the issue of non-determinism. The authors say that since the simulation is averaged over multiple trials, random variations in this part of the code should not matter. The original poster explains some disagreement, and the authors never actually respond to that; instead, they say that "Since misunderstanding and misuse continues," they changed this section to be single-threaded, with "no significant change to results." but I'm not sure what level of significance they are testing or what output they are referring to.

To satisfyingly answer that question, it would be interesting if we could reproduce the graphs in Report 9, but even with this code we cannot, because we don't know the actual input configuration that Ferguson used. When asked for the original configuration, the <a href="https://github.com/mrc-ide/covid-sim/issues/144#issuecomment-625225840">authors stated</a> that "Many tens of thousands of runs contributed to the spread of results in Report 9. Right now, I'm afraid the process for lay users is to pick values out of the ranges described in the report." It would be nice if they could at least release the outputs from those runs, but the authors say (in the same thread) they didn't have the resources to save the outputs or a summary of them, except for the figure in Report 9. Later on, they say that one of the data inputs to Report 9 was proprietary, so we couldn't reproduce it anyway.

Yet, some of this was obviously due to the stress in-the-moment. <a href="https://cacm.acm.org/blogs/blog-cacm/246511-the-software-that-led-to-the-lockdown/fulltext">The same model predicted</a> that "if the U.K. had locked down just one week earlier than it did, then 20,000 lives might have been saved."

I think a good takeaway from the situation is that it's easier to have good coding practices from the start than do the quick-and-dirty solution. Otherwise, you'll have to do a lot of cleanup when you publish, and it's harder to have confidence in the results.
